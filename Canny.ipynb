{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iuri/regressionml/blob/main/Canny.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, os, time \n",
        "from google.colab import drive\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import os\n",
        "import numpy as np\n",
        "import time \n"
      ],
      "metadata": {
        "id": "naItKLe1zx2C"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "# utils.py\n",
        "###\n",
        "def plot_image(image, figsize = 10, cvtColorParam=None):\n",
        "    plt.figure(figsize = (figsize, figsize))\n",
        "\n",
        "    # plt.subplot(figsize[0], figsize[1], i+1)\n",
        "    if cvtColorParam != None:\n",
        "        image = cv2.cvtColor(image, cvtColorParam)\n",
        "\n",
        "    plt.imshow(image)    #If the image is grayscale, as in our case, then we will reshape the output in the following way.\n",
        "                                                                        #Also, we set the coloring to grayscale so that it doesn't look like it came out of an infrared camera :)\n",
        "    # else:\n",
        "    #     plt.imshow(image.reshape((img_rows, img_cols, 1)))\n",
        "    plt.axis('off')\n",
        "\n",
        "    # plt.tight_layout()   #Tight layout so that all of the generated images form a nice grid\n",
        "        \n",
        "    plt.show()\n",
        "\n",
        "def get_image_from_webcam():\n",
        "    # Webcam\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    success, img = cap.read()\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    cap.release()\n",
        "\n",
        "    return img\n",
        "    \n",
        "def save_image_from_webcam(folder):\n",
        "    # Webcam\n",
        "    img = get_image_from_webcam()\n",
        "    name = f\"{folder}/{datetime.datetime.now()}.png\"\n",
        "    cv2.imwrite(name , img)\n",
        "\n",
        "    return name\n",
        "\n",
        "def save_image(cv2image, filename=f\"assets/{datetime.datetime.now()}.png\"):\n",
        "    sucess = cv2.imwrite(filename , cv2image)\n",
        "    print(f'Imagem salva em: {filename}')\n",
        "    return sucess\n",
        "\n",
        "\n",
        "#Função para retornar tamanho da amostra e passo nos frames\n",
        "def amostra(n_frames, e):\n",
        "    import math\n",
        "    import scipy.stats as st    \n",
        "    \n",
        "    Z = st.norm.ppf(1 - e/2) #Z-escore\n",
        "    P = 0.50 #Desvio padrão \n",
        "    C = (Z**2)*P*(1-P)/(e**2) #Constante\n",
        "    amos = math.ceil(C/(1 + C/n_frames))\n",
        "    step = math.floor(n_frames/amos)\n",
        "    return amos, step\n",
        "\n",
        "def extract_images_from_video(file, error_rate = 0.1):\n",
        "    import cv2\n",
        "\n",
        "    video = cv2.VideoCapture(file)\n",
        "    n_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    e = float(error_rate)\n",
        "    \n",
        "    amos, step = amostra(n_frames, e)\n",
        "    \n",
        "    images = []\n",
        "    success, frame = video.read()\n",
        "    start = 0\n",
        "\n",
        "    while success and start + step <= n_frames:   \n",
        "        images.append(frame)\n",
        "        save_image(frame, f'assets/dataset/{start + step}.png')\n",
        "\n",
        "        #Extrai frames específicos a cada passo\n",
        "        video.set(cv2.CAP_PROP_POS_FRAMES, (start + step))\n",
        "        success, frame = video.read()\n",
        "\n",
        "        start += step\n",
        "\n",
        "    return images\n",
        "\n",
        "def get_images_from_folder(folder, cutArray = []):\n",
        "    # cut=(50:600, 330:950)\n",
        "    # import glob\n",
        "\n",
        "    filenames = sorted(glob.glob(f'{folder}/*.png'))    \n",
        "#    filenames = sorted(glob.glob(f'{folder}/*.png'), key=os.path.getmtime)\n",
        "    images = []\n",
        "\n",
        "    for file in filenames:\n",
        "        img = cv2.imread(file)\n",
        "        if len(cutArray) > 0:\n",
        "            images.append(\n",
        "                img[\n",
        "                    cutArray[0] : cutArray[1], \n",
        "                    cutArray[2] : cutArray[3]\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            images.append(img)\n",
        "\n",
        "    return images, filenames\n",
        "\n",
        "def label_on_image(image, text, color = (0,0,255)):\n",
        "    i = image.copy()\n",
        "    cv2.putText(i, text, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
        "    return i \n",
        "\n",
        "def auto_canny(image, sigma=0.33):\n",
        "    import argparse\n",
        "\t\n",
        "    # compute the median of the single channel pixel intensities\n",
        "    v = np.median(image)\n",
        "\t# apply automatic Canny edge detection using the computed median\n",
        "    lower = int(max(0, (1.0 - sigma) * v))\n",
        "    upper = int(min(255, (1.0 + sigma) * v))\n",
        "    edged = cv2.Canny(image, lower, upper)\n",
        "    \n",
        "    # return the edged image\n",
        "    return edged\n",
        "\n",
        "def play_images(all_images, rows = 1, columns = 1, sec = 60, time_between_frames = 0.2):\n",
        "    height = all_images[0][0].shape[0]*rows\n",
        "    width = all_images[0][0].shape[1]*columns\n",
        "\n",
        "    n_frames = len(all_images[0])\n",
        "    fps = n_frames // sec\n",
        "\n",
        "    print(f'FPS: {fps}', f'height: {height}',f'width: {width}')\n",
        "\n",
        "    for i in range(n_frames):\n",
        "        if rows == 1:\n",
        "            if columns == 1:\n",
        "                im2show = np.hstack([all_images[0][i]])\n",
        "\n",
        "            elif columns == 2:\n",
        "                im2show = np.hstack([all_images[0][i], all_images[1][i]])\n",
        "            \n",
        "            elif columns == 3:\n",
        "                im2show = np.hstack([all_images[0][i], all_images[1][i], all_images[2][i]])\n",
        "            \n",
        "            elif columns == 4:\n",
        "                im2show = np.hstack([all_images[0][i], all_images[1][i], all_images[2][i], all_images[3][i]])\n",
        "\n",
        "        elif rows == 2:\n",
        "            if columns == 1:\n",
        "                im2show = np.vstack([\n",
        "                    np.hstack([all_images[0][i]]),\n",
        "                    np.hstack([all_images[1][i]]),\n",
        "                ])\n",
        "\n",
        "            elif columns == 2:\n",
        "                im2show = np.vstack([\n",
        "                    np.hstack([all_images[0][i], all_images[1][i]]),\n",
        "                    np.hstack([all_images[2][i], all_images[3][i]])\n",
        "                ])\n",
        "\n",
        "            elif columns == 3:\n",
        "                im2show = np.vstack([\n",
        "                    np.hstack([all_images[0][i], all_images[1][i], all_images[2][i]]),\n",
        "                    np.hstack([all_images[3][i], all_images[4][i], all_images[5][i]])\n",
        "                ])\n",
        "\n",
        "            elif columns == 4:\n",
        "                im2show = np.vstack([\n",
        "                    np.hstack([all_images[0][i], all_images[1][i], all_images[2][i], all_images[3][i]]),\n",
        "                    np.hstack([all_images[4][i], all_images[5][i], all_images[6][i], all_images[7][i]])\n",
        "                ])\n",
        "                \n",
        "        cv2.imshow(\"image\", im2show)\n",
        "        k = cv2.waitKey(30) & 0xff\n",
        "        if k == 27: \n",
        "            break\n",
        "\n",
        "        time.sleep(time_between_frames)\n",
        "\n",
        "    print(f'Stopped at frame {i}')\n",
        "    cv2.destroyAllWindows() \n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "zuzG1JV_u6C7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQt0ALEjuuAu",
        "outputId": "308ac453-7e36-4b3a-fdeb-bf9b0f69964f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# to mount Google Drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(\"/content/gdrive/MyDrive/BKP/MESTRADO/dataset/temp\"))"
      ],
      "metadata": {
        "id": "7GjBhFWSRYHG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15352029-1707-4c8d-a777-ae93816e36ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Cópia de 3761.png', 'Cópia de 3755.png', 'Cópia de 3758.png', 'Cópia de 3757.png', 'Cópia de 3760.png', 'Cópia de 3756.png', 'Cópia de 3753.png', 'Cópia de 3754.png', 'Cópia de 3762.png', 'Cópia de 3759.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"/content/gdrive/MyDrive/BKP/MESTRADO/dataset/temp\""
      ],
      "metadata": {
        "id": "YiFuUdiYTV48"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XHwPIFqguuAv"
      },
      "outputs": [],
      "source": [
        "# images, files = get_images_from_folder(folder, cutArray=[50,600,330,950])\n",
        "cutArray = []\n",
        "filenames = sorted(glob.glob(f'{folder}/*.png'))    \n",
        "images = []\n",
        "for file in filenames:\n",
        "    img = cv2.imread(file)\n",
        "    if len(cutArray) > 0:\n",
        "        images.append(\n",
        "            img[\n",
        "                cutArray[0] : cutArray[1], \n",
        "                cutArray[2] : cutArray[3]\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        images.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LBUfFUiLuuAv",
        "outputId": "ef786490-5f81-4b34-b200-77c460350fe0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Foram carregadas 58 imagens'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "f'Foram carregadas {len(images)} imagens'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "209jqC3MuuAw",
        "outputId": "d9259f66-0148-437f-92bf-86154a5de184"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('FPS: 0', 'height: 1920', 'width: 3840')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "sec = 60\n",
        "rows = 2\n",
        "columns = 3\n",
        "height = images[0].shape[0]*rows\n",
        "width = images[0].shape[1]*columns\n",
        "n_frames = len(images)\n",
        "fps = n_frames // sec\n",
        "f'FPS: {fps}', f'height: {height}',f'width: {width}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "hEzbf0jNuuAx",
        "outputId": "650bf2c4-7da4-4119-a184-67311ef125d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-9f41765e5b93>:11: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  if image != 'None':\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "DisabledFunctionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDisabledFunctionError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-9f41765e5b93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m          ])\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m          \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim2show\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m          \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim2show\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_import_hooks/_cv2.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisabledFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDisabledFunctionError\u001b[0m: cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_snippet",
                "actionText": "Search Snippets for cv2.imshow",
                "snippetFilter": "cv2.imshow"
              }
            ]
          }
        }
      ],
      "source": [
        "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
        "video = cv2.VideoWriter(\"outputs/canny.mp4\", fourcc, float(fps), (width, height))\n",
        " \n",
        "a = 75\n",
        "b = 175\n",
        "    \n",
        "for image in images:\n",
        "   if image is not None:\n",
        "     #print(\"yes\")\n",
        "     if image.any():\n",
        "       if image != 'None':\n",
        "         frame = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "         frame = cv2.GaussianBlur(frame,(7,7), 0)\n",
        "         # Canny from image\n",
        "         suavizacao = cv2.GaussianBlur(frame,(7,7), 0)\n",
        "         canny_from_frame = cv2.Canny(suavizacao, a, b)#, L2gradient = True)\n",
        "         # canny_from_frame = cv2.bitwise_and(frame, frame, mask=canny_from_frame)\n",
        "         canny_from_frame = cv2.cvtColor(canny_from_frame, cv2.COLOR_GRAY2BGR)\n",
        "         # threshold\n",
        "         thresh = cv2.threshold(frame, 60, 255, cv2.THRESH_BINARY)[1]\n",
        "         # morphology edgeout = dilated_mask - mask\n",
        "         # morphology dilate\n",
        "         kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
        "         dilate = cv2.morphologyEx(thresh, cv2.MORPH_DILATE, kernel)\n",
        "         # get absolute difference between dilate and thresh\n",
        "         diff = cv2.absdiff(dilate, thresh)\n",
        "         # invert\n",
        "         edges = 255 - diff\n",
        "         edges = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "         ret, img_otsu = cv2.threshold(suavizacao, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "         canny_from_otsu = cv2.Canny(img_otsu, a, b)\n",
        "         canny_from_otsu = cv2.cvtColor(canny_from_otsu, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "         autoCannyOtsu = auto_canny(img_otsu)\n",
        "         autoCannyOtsu = cv2.cvtColor(autoCannyOtsu, cv2.COLOR_GRAY2BGR)\n",
        "          \n",
        "         autoCanny = auto_canny(frame)\n",
        "         autoCanny = cv2.cvtColor(autoCanny, cv2.COLOR_GRAY2BGR)\n",
        "          \n",
        "         img_otsu = cv2.bitwise_not(img_otsu)\n",
        "         img_otsu = cv2.cvtColor(img_otsu, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "\n",
        "         # Labels on images\n",
        "         image = label_on_image(image, \"Real\")\n",
        "         img_otsu = label_on_image(img_otsu, \"Threshold OTSU\")\n",
        "         canny_from_frame = label_on_image(canny_from_frame, \"Canny\")\n",
        "         # autoCanny2 = label_on_image(autoCanny2, \"Auto canny 0.66\")\n",
        "         autoCanny = label_on_image(autoCanny, \"Auto canny\")\n",
        "         edges = label_on_image(edges, \"edges\")\n",
        "         canny_from_otsu = label_on_image(canny_from_otsu, \"Canny from OTSU\")\n",
        "         autoCannyOtsu = label_on_image(autoCannyOtsu, \"Autocanny from otsu\")\n",
        "         im2show = np.vstack([\n",
        "             np.hstack([image, canny_from_frame, autoCanny]),\n",
        "             np.hstack([img_otsu, canny_from_otsu, autoCannyOtsu])\n",
        "             # np.hstack([canny_from_frame, sobel, laplacian])\n",
        "         ])\n",
        "\n",
        "         cv2.imshow(\"image\", im2show)\n",
        "\n",
        "         video.write(im2show)\n",
        "\n",
        "         k = cv2.waitKey(30) & 0xff\n",
        "         if k == 27: \n",
        "           break\n",
        "         time.sleep(0.2)\n",
        "\n",
        "cv2.destroyAllWindows() \n",
        "    \n",
        "video.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndBQxdEGuuAy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "softrobots",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "1d26d290b529236eaeb03f94fde4acf44ad14017a7ce49efd85bc2ab3bc7dd9e"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}